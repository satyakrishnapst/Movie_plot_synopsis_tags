{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a7kmc4ayLbjU",
    "outputId": "ffca431d-831a-4221-f59d-39cd3963c970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RX4p9neXK1TR"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime\n",
    "from scipy.sparse import coo_matrix, hstack \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "#keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.regularizers import l1,l2\n",
    "from scipy.sparse import hstack\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorboardcolab import * \n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "wwhsl6ATLjkK",
    "outputId": "495e7086-628c-4702-bae9-1e2d6bc755d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>tags_count</th>\n",
       "      <th>tags_2</th>\n",
       "      <th>pre_pro_title</th>\n",
       "      <th>pre_pro_plot_synopsis</th>\n",
       "      <th>pre_pro_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>5</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>tre volti della paura</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>violence</td>\n",
       "      <td>dungeons dragons book vile darkness</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "      <td>violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>romantic</td>\n",
       "      <td>shop around corner</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>4</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>mr holland opus</td>\n",
       "      <td>glenn holland not morning person anyone standa...</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>imdb</td>\n",
       "      <td>10</td>\n",
       "      <td>cruelty murder dramatic cult violence atmosphe...</td>\n",
       "      <td>scarface</td>\n",
       "      <td>may 1980 cuban man named tony montana al pacin...</td>\n",
       "      <td>cruelty murder dramatic cult violence atmosphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    imdb_id                                          title  \\\n",
       "0           0  tt0057603                        I tre volti della paura   \n",
       "1           1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2           2  tt0033045                     The Shop Around the Corner   \n",
       "3           3  tt0113862                             Mr. Holland's Opus   \n",
       "4           4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split synopsis_source  \\\n",
       "0          cult, horror, gothic, murder, atmospheric  train            imdb   \n",
       "1                                           violence  train            imdb   \n",
       "2                                           romantic   test            imdb   \n",
       "3             inspiring, romantic, stupid, feel-good  train            imdb   \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val            imdb   \n",
       "\n",
       "   tags_count                                             tags_2  \\\n",
       "0           5              cult horror gothic murder atmospheric   \n",
       "1           1                                           violence   \n",
       "2           1                                           romantic   \n",
       "3           4                inspiring romantic stupid feel-good   \n",
       "4          10  cruelty murder dramatic cult violence atmosphe...   \n",
       "\n",
       "                         pre_pro_title  \\\n",
       "0                tre volti della paura   \n",
       "1  dungeons dragons book vile darkness   \n",
       "2                   shop around corner   \n",
       "3                      mr holland opus   \n",
       "4                             scarface   \n",
       "\n",
       "                               pre_pro_plot_synopsis  \\\n",
       "0  note synopsis orginal italian release segments...   \n",
       "1  two thousand years ago nhagruul foul sorcerer ...   \n",
       "2  matuschek gift store budapest workplace alfred...   \n",
       "3  glenn holland not morning person anyone standa...   \n",
       "4  may 1980 cuban man named tony montana al pacin...   \n",
       "\n",
       "                                        pre_pro_tags  \n",
       "0              cult horror gothic murder atmospheric  \n",
       "1                                           violence  \n",
       "2                                           romantic  \n",
       "3                inspiring romantic stupid feel-good  \n",
       "4  cruelty murder dramatic cult violence atmosphe...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_df = pd.read_csv('pure_df.csv')\n",
    "pure_df.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qicQMM8ROV-S"
   },
   "source": [
    "<h3>Topic_Modelling</h3>\n",
    " code_ref : <a href>https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "tPJ6bCxdLjqm",
    "outputId": "6f074431-1deb-4ad8-9c0c-66c0af700e6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>tags_count</th>\n",
       "      <th>tags_2</th>\n",
       "      <th>pre_pro_title</th>\n",
       "      <th>pre_pro_plot_synopsis</th>\n",
       "      <th>pre_pro_tags</th>\n",
       "      <th>pre_pro_plot_synopsis_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>5</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>tre volti della paura</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>[note, synopsis, orginal, italian, release, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>violence</td>\n",
       "      <td>dungeons dragons book vile darkness</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "      <td>violence</td>\n",
       "      <td>[two, thousand, years, ago, nhagruul, foul, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>romantic</td>\n",
       "      <td>shop around corner</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>[matuschek, gift, store, budapest, workplace, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>4</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>mr holland opus</td>\n",
       "      <td>glenn holland not morning person anyone standa...</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>[glenn, holland, not, morning, person, anyone,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>imdb</td>\n",
       "      <td>10</td>\n",
       "      <td>cruelty murder dramatic cult violence atmosphe...</td>\n",
       "      <td>scarface</td>\n",
       "      <td>may 1980 cuban man named tony montana al pacin...</td>\n",
       "      <td>cruelty murder dramatic cult violence atmosphe...</td>\n",
       "      <td>[may, 1980, cuban, man, named, tony, montana, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    imdb_id                                          title  \\\n",
       "0           0  tt0057603                        I tre volti della paura   \n",
       "1           1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2           2  tt0033045                     The Shop Around the Corner   \n",
       "3           3  tt0113862                             Mr. Holland's Opus   \n",
       "4           4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split synopsis_source  \\\n",
       "0          cult, horror, gothic, murder, atmospheric  train            imdb   \n",
       "1                                           violence  train            imdb   \n",
       "2                                           romantic   test            imdb   \n",
       "3             inspiring, romantic, stupid, feel-good  train            imdb   \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val            imdb   \n",
       "\n",
       "   tags_count                                             tags_2  \\\n",
       "0           5              cult horror gothic murder atmospheric   \n",
       "1           1                                           violence   \n",
       "2           1                                           romantic   \n",
       "3           4                inspiring romantic stupid feel-good   \n",
       "4          10  cruelty murder dramatic cult violence atmosphe...   \n",
       "\n",
       "                         pre_pro_title  \\\n",
       "0                tre volti della paura   \n",
       "1  dungeons dragons book vile darkness   \n",
       "2                   shop around corner   \n",
       "3                      mr holland opus   \n",
       "4                             scarface   \n",
       "\n",
       "                               pre_pro_plot_synopsis  \\\n",
       "0  note synopsis orginal italian release segments...   \n",
       "1  two thousand years ago nhagruul foul sorcerer ...   \n",
       "2  matuschek gift store budapest workplace alfred...   \n",
       "3  glenn holland not morning person anyone standa...   \n",
       "4  may 1980 cuban man named tony montana al pacin...   \n",
       "\n",
       "                                        pre_pro_tags  \\\n",
       "0              cult horror gothic murder atmospheric   \n",
       "1                                           violence   \n",
       "2                                           romantic   \n",
       "3                inspiring romantic stupid feel-good   \n",
       "4  cruelty murder dramatic cult violence atmosphe...   \n",
       "\n",
       "                         pre_pro_plot_synopsis_words  \n",
       "0  [note, synopsis, orginal, italian, release, se...  \n",
       "1  [two, thousand, years, ago, nhagruul, foul, so...  \n",
       "2  [matuschek, gift, store, budapest, workplace, ...  \n",
       "3  [glenn, holland, not, morning, person, anyone,...  \n",
       "4  [may, 1980, cuban, man, named, tony, montana, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_df['pre_pro_plot_synopsis_words']=pure_df['pre_pro_plot_synopsis'].apply(lambda x: x.split())\n",
    "pure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3e6YaOULjuQ"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(pure_df['pre_pro_plot_synopsis_words'])\n",
    "\n",
    "# Create Corpus\n",
    "texts = pure_df['pre_pro_plot_synopsis_words']\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NUUl11YVLj2E",
    "outputId": "7456577e-b671-42d4-fb45-5ff6da172b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1), (12, 2), (13, 1), (14, 1), (15, 4), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 5), (38, 2), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 3), (54, 1), (55, 4), (56, 3), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 2), (72, 5), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 3), (82, 1), (83, 6), (84, 2), (85, 1), (86, 1), (87, 2), (88, 1), (89, 2), (90, 2), (91, 1), (92, 1), (93, 1), (94, 2), (95, 4), (96, 1), (97, 5), (98, 2), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 2), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 2), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 2), (146, 1), (147, 1), (148, 1), (149, 3), (150, 1), (151, 1), (152, 1), (153, 1), (154, 7), (155, 3), (156, 3), (157, 1), (158, 2), (159, 1), (160, 1), (161, 2), (162, 3), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 3), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 5), (177, 1), (178, 1), (179, 2), (180, 1), (181, 1), (182, 2), (183, 1), (184, 6), (185, 1), (186, 1), (187, 1), (188, 1), (189, 2), (190, 1), (191, 7), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 2), (205, 1), (206, 1), (207, 4), (208, 1), (209, 2), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 2), (221, 2), (222, 1), (223, 1), (224, 1), (225, 1), (226, 3), (227, 1), (228, 1), (229, 1), (230, 1), (231, 3), (232, 1), (233, 1), (234, 5), (235, 1), (236, 1), (237, 1), (238, 1), (239, 4), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 2), (247, 1), (248, 1), (249, 1), (250, 1), (251, 2), (252, 1), (253, 1), (254, 1), (255, 2), (256, 1), (257, 1), (258, 1), (259, 2), (260, 1), (261, 1), (262, 1), (263, 4), (264, 1), (265, 2), (266, 1), (267, 1), (268, 6), (269, 1), (270, 1), (271, 1), (272, 1), (273, 2), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 7), (289, 4), (290, 2), (291, 1), (292, 2), (293, 1), (294, 1), (295, 2), (296, 6), (297, 1), (298, 1), (299, 1), (300, 1), (301, 3), (302, 5), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 2), (314, 1), (315, 1), (316, 4), (317, 1), (318, 2), (319, 1), (320, 1), (321, 1), (322, 1), (323, 1), (324, 1), (325, 1), (326, 1), (327, 1), (328, 1), (329, 1), (330, 1), (331, 2), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 2), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1), (349, 1), (350, 1), (351, 1), (352, 4), (353, 1), (354, 1), (355, 1), (356, 2), (357, 1), (358, 1), (359, 3), (360, 1), (361, 1), (362, 13), (363, 1), (364, 1), (365, 1), (366, 1), (367, 1), (368, 1), (369, 1), (370, 3), (371, 1), (372, 7), (373, 1), (374, 1), (375, 1), (376, 1), (377, 1), (378, 1), (379, 1), (380, 1), (381, 1), (382, 1), (383, 1), (384, 1), (385, 1), (386, 1), (387, 1), (388, 1), (389, 2), (390, 1), (391, 3), (392, 1), (393, 1), (394, 2), (395, 2), (396, 2), (397, 1), (398, 1), (399, 1), (400, 1), (401, 1), (402, 1), (403, 1), (404, 1), (405, 1), (406, 2), (407, 1), (408, 1), (409, 1), (410, 1), (411, 3), (412, 1), (413, 2), (414, 1), (415, 1), (416, 1), (417, 1), (418, 2), (419, 1), (420, 1), (421, 1), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (427, 1), (428, 2), (429, 1), (430, 1), (431, 2), (432, 1), (433, 1), (434, 1), (435, 1), (436, 2), (437, 1), (438, 1), (439, 3), (440, 1), (441, 1), (442, 2), (443, 1), (444, 1), (445, 1), (446, 1), (447, 1), (448, 1), (449, 1), (450, 3), (451, 1), (452, 1), (453, 1), (454, 1), (455, 1), (456, 1), (457, 1), (458, 1), (459, 1), (460, 1), (461, 1), (462, 1), (463, 10), (464, 2), (465, 1), (466, 1), (467, 2), (468, 1), (469, 2), (470, 1), (471, 1), (472, 2), (473, 1), (474, 1), (475, 3), (476, 1), (477, 1), (478, 1), (479, 1), (480, 1), (481, 1), (482, 4), (483, 1), (484, 4), (485, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "l-cdMvNzLjzZ",
    "outputId": "c32c7895-bf4b-4907-d9ff-1b7c8e49a58f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('19th', 1),\n",
       "  ('abandoned', 2),\n",
       "  ('abby', 1),\n",
       "  ('absence', 1),\n",
       "  ('acquisition', 1),\n",
       "  ('actually', 1),\n",
       "  ('agrees', 2),\n",
       "  ('aid', 2),\n",
       "  ('air', 1),\n",
       "  ('alfonsi', 1),\n",
       "  ('ali', 2),\n",
       "  ('already', 1),\n",
       "  ('also', 2),\n",
       "  ('anderson', 1),\n",
       "  ('anticipating', 1),\n",
       "  ('apartment', 4),\n",
       "  ('apparently', 1),\n",
       "  ('appearance', 2),\n",
       "  ('appears', 1),\n",
       "  ('arms', 1),\n",
       "  ('around', 1),\n",
       "  ('arrival', 1),\n",
       "  ('arrives', 2),\n",
       "  ('ask', 1),\n",
       "  ('assailed', 2),\n",
       "  ('attacked', 1),\n",
       "  ('attempts', 1),\n",
       "  ('attracted', 1),\n",
       "  ('attractive', 1),\n",
       "  ('await', 1),\n",
       "  ('awaken', 1),\n",
       "  ('awakened', 1),\n",
       "  ('awakens', 1),\n",
       "  ('away', 1),\n",
       "  ('back', 2),\n",
       "  ('basement', 1),\n",
       "  ('battle', 1),\n",
       "  ('bed', 5),\n",
       "  ('beg', 2),\n",
       "  ('begin', 1),\n",
       "  ('beginning', 1),\n",
       "  ('begs', 2),\n",
       "  ('beheaded', 1),\n",
       "  ('beheads', 1),\n",
       "  ('behind', 1),\n",
       "  ('believes', 1),\n",
       "  ('belongs', 1),\n",
       "  ('beset', 1),\n",
       "  ('best', 1),\n",
       "  ('bite', 1),\n",
       "  ('bites', 1),\n",
       "  ('bits', 1),\n",
       "  ('blade', 1),\n",
       "  ('blood', 3),\n",
       "  ('bode', 1),\n",
       "  ('body', 4),\n",
       "  ('boris', 3),\n",
       "  ('branches', 1),\n",
       "  ('breaks', 2),\n",
       "  ('breakup', 1),\n",
       "  ('brother', 1),\n",
       "  ('brothers', 1),\n",
       "  ('bruise', 1),\n",
       "  ('burial', 1),\n",
       "  ('bury', 1),\n",
       "  ('busy', 1),\n",
       "  ('butcher', 1),\n",
       "  ('buzzing', 1),\n",
       "  ('cadaver', 1),\n",
       "  ('call', 2),\n",
       "  ('called', 1),\n",
       "  ('caller', 2),\n",
       "  ('calls', 5),\n",
       "  ('calm', 1),\n",
       "  ('camera', 1),\n",
       "  ('careful', 1),\n",
       "  ('caring', 1),\n",
       "  ('case', 1),\n",
       "  ('cathedral', 1),\n",
       "  ('caused', 1),\n",
       "  ('century', 1),\n",
       "  ('certain', 3),\n",
       "  ('change', 1),\n",
       "  ('chester', 6),\n",
       "  ('child', 2),\n",
       "  ('close', 1),\n",
       "  ('come', 1),\n",
       "  ('coming', 2),\n",
       "  ('commit', 1),\n",
       "  ('concierge', 2),\n",
       "  ('concludes', 2),\n",
       "  ('confession', 1),\n",
       "  ('confirmed', 1),\n",
       "  ('confused', 1),\n",
       "  ('continues', 2),\n",
       "  ('corpse', 4),\n",
       "  ('corpses', 1),\n",
       "  ('cottage', 5),\n",
       "  ('count', 2),\n",
       "  ('course', 1),\n",
       "  ('creeps', 1),\n",
       "  ('crew', 1),\n",
       "  ('crewmen', 1),\n",
       "  ('curse', 1),\n",
       "  ('daggers', 1),\n",
       "  ('daughter', 1),\n",
       "  ('dawn', 1),\n",
       "  ('days', 1),\n",
       "  ('de', 1),\n",
       "  ('dead', 1),\n",
       "  ('death', 2),\n",
       "  ('decides', 1),\n",
       "  ('decision', 1),\n",
       "  ('demeanor', 1),\n",
       "  ('dialina', 1),\n",
       "  ('diamond', 1),\n",
       "  ('died', 1),\n",
       "  ('difficult', 1),\n",
       "  ('discovered', 2),\n",
       "  ('discovers', 1),\n",
       "  ('distinct', 1),\n",
       "  ('distracted', 1),\n",
       "  ('distressed', 1),\n",
       "  ('doctor', 1),\n",
       "  ('door', 1),\n",
       "  ('doubt', 1),\n",
       "  ('drains', 1),\n",
       "  ('dreaded', 1),\n",
       "  ('dressed', 1),\n",
       "  ('dripping', 1),\n",
       "  ('drop', 1),\n",
       "  ('drops', 2),\n",
       "  ('duty', 1),\n",
       "  ('eagerly', 1),\n",
       "  ('earlier', 1),\n",
       "  ('east', 1),\n",
       "  ('elaborate', 1),\n",
       "  ('elderly', 1),\n",
       "  ('embraces', 1),\n",
       "  ('end', 1),\n",
       "  ('england', 1),\n",
       "  ('entrance', 1),\n",
       "  ('escape', 1),\n",
       "  ('escaped', 1),\n",
       "  ('estranged', 1),\n",
       "  ('evening', 2),\n",
       "  ('events', 1),\n",
       "  ('ex', 1),\n",
       "  ('examine', 1),\n",
       "  ('explains', 3),\n",
       "  ('face', 1),\n",
       "  ('faces', 1),\n",
       "  ('fails', 1),\n",
       "  ('fake', 1),\n",
       "  ('family', 7),\n",
       "  ('father', 3),\n",
       "  ('fear', 3),\n",
       "  ('fears', 1),\n",
       "  ('feeds', 2),\n",
       "  ('felt', 1),\n",
       "  ('final', 1),\n",
       "  ('finds', 2),\n",
       "  ('finger', 3),\n",
       "  ('finishes', 1),\n",
       "  ('fit', 1),\n",
       "  ('five', 1),\n",
       "  ('flat', 1),\n",
       "  ('flee', 1),\n",
       "  ('flees', 1),\n",
       "  ('floor', 1),\n",
       "  ('fly', 3),\n",
       "  ('follow', 1),\n",
       "  ('forcing', 1),\n",
       "  ('forest', 1),\n",
       "  ('forgiveness', 1),\n",
       "  ('former', 1),\n",
       "  ('frank', 5),\n",
       "  ('franks', 1),\n",
       "  ('friends', 1),\n",
       "  ('fright', 2),\n",
       "  ('front', 1),\n",
       "  ('gasps', 1),\n",
       "  ('gets', 2),\n",
       "  ('ghosts', 1),\n",
       "  ('giorgio', 6),\n",
       "  ('girl', 1),\n",
       "  ('gives', 1),\n",
       "  ('glass', 1),\n",
       "  ('glauco', 1),\n",
       "  ('go', 2),\n",
       "  ('gone', 1),\n",
       "  ('gorcha', 7),\n",
       "  ('grave', 1),\n",
       "  ('greed', 1),\n",
       "  ('greeted', 1),\n",
       "  ('gripping', 1),\n",
       "  ('gustavo', 1),\n",
       "  ('hands', 1),\n",
       "  ('hanging', 1),\n",
       "  ('happens', 1),\n",
       "  ('happy', 1),\n",
       "  ('harriet', 1),\n",
       "  ('heart', 1),\n",
       "  ('helen', 1),\n",
       "  ('help', 2),\n",
       "  ('hide', 1),\n",
       "  ('high', 1),\n",
       "  ('home', 4),\n",
       "  ('horror', 1),\n",
       "  ('horse', 2),\n",
       "  ('house', 1),\n",
       "  ('however', 1),\n",
       "  ('husband', 1),\n",
       "  ('hysteria', 1),\n",
       "  ('identified', 1),\n",
       "  ('image', 1),\n",
       "  ('imaging', 1),\n",
       "  ('immediately', 1),\n",
       "  ('impersonating', 1),\n",
       "  ('infected', 1),\n",
       "  ('infects', 2),\n",
       "  ('introduces', 2),\n",
       "  ('intruder', 1),\n",
       "  ('investigator', 1),\n",
       "  ('invited', 1),\n",
       "  ('italian', 1),\n",
       "  ('ivan', 3),\n",
       "  ('jacqueline', 1),\n",
       "  ('jail', 1),\n",
       "  ('job', 1),\n",
       "  ('journey', 1),\n",
       "  ('karloff', 3),\n",
       "  ('kill', 1),\n",
       "  ('killed', 1),\n",
       "  ('knife', 5),\n",
       "  ('knowing', 1),\n",
       "  ('known', 1),\n",
       "  ('landed', 1),\n",
       "  ('large', 1),\n",
       "  ('later', 4),\n",
       "  ('law', 1),\n",
       "  ('learned', 1),\n",
       "  ('leave', 1),\n",
       "  ('left', 1),\n",
       "  ('lesbian', 1),\n",
       "  ('lies', 1),\n",
       "  ('life', 2),\n",
       "  ('lights', 1),\n",
       "  ('likely', 1),\n",
       "  ('living', 1),\n",
       "  ('london', 1),\n",
       "  ('long', 2),\n",
       "  ('longer', 1),\n",
       "  ('looking', 1),\n",
       "  ('love', 1),\n",
       "  ('lover', 2),\n",
       "  ('lovers', 1),\n",
       "  ('loving', 1),\n",
       "  ('lured', 1),\n",
       "  ('lying', 2),\n",
       "  ('lynda', 1),\n",
       "  ('macabre', 1),\n",
       "  ('maddening', 1),\n",
       "  ('makes', 4),\n",
       "  ('making', 1),\n",
       "  ('man', 2),\n",
       "  ('mans', 1),\n",
       "  ('marry', 1),\n",
       "  ('mary', 6),\n",
       "  ('massimo', 1),\n",
       "  ('matter', 1),\n",
       "  ('meant', 1),\n",
       "  ('medin', 1),\n",
       "  ('medium', 2),\n",
       "  ('members', 1),\n",
       "  ('mercier', 1),\n",
       "  ('michele', 1),\n",
       "  ('midnight', 1),\n",
       "  ('morning', 1),\n",
       "  ('mostly', 1),\n",
       "  ('mother', 1),\n",
       "  ('motionless', 1),\n",
       "  ('moving', 1),\n",
       "  ('murderous', 1),\n",
       "  ('nardo', 1),\n",
       "  ('necessary', 1),\n",
       "  ('nerves', 1),\n",
       "  ('next', 1),\n",
       "  ('night', 7),\n",
       "  ('no', 4),\n",
       "  ('nobleman', 2),\n",
       "  ('not', 1),\n",
       "  ('note', 2),\n",
       "  ('notes', 1),\n",
       "  ('notice', 1),\n",
       "  ('notices', 2),\n",
       "  ('nurse', 6),\n",
       "  ('nylon', 1),\n",
       "  ('observation', 1),\n",
       "  ('odor', 1),\n",
       "  ('offers', 1),\n",
       "  ('old', 3),\n",
       "  ('one', 5),\n",
       "  ('onorato', 1),\n",
       "  ('optimistic', 1),\n",
       "  ('order', 1),\n",
       "  ('orginal', 1),\n",
       "  ('outlaw', 1),\n",
       "  ('panic', 1),\n",
       "  ('parisian', 1),\n",
       "  ('pathologist', 1),\n",
       "  ('pens', 1),\n",
       "  ('pester', 1),\n",
       "  ('phone', 2),\n",
       "  ('phones', 1),\n",
       "  ('pierreux', 1),\n",
       "  ('pietro', 4),\n",
       "  ('pillow', 1),\n",
       "  ('pimp', 2),\n",
       "  ('placed', 1),\n",
       "  ('pleased', 1),\n",
       "  ('plunged', 1),\n",
       "  ('police', 1),\n",
       "  ('possibility', 1),\n",
       "  ('precautions', 1),\n",
       "  ('preferably', 1),\n",
       "  ('prepare', 1),\n",
       "  ('prevent', 1),\n",
       "  ('prevented', 1),\n",
       "  ('priced', 1),\n",
       "  ('pried', 1),\n",
       "  ('prison', 2),\n",
       "  ('promising', 1),\n",
       "  ('prop', 1),\n",
       "  ('protection', 1),\n",
       "  ('pulls', 1),\n",
       "  ('puts', 1),\n",
       "  ('quickly', 1),\n",
       "  ('reach', 1),\n",
       "  ('real', 1),\n",
       "  ('realize', 2),\n",
       "  ('realizes', 1),\n",
       "  ('reason', 1),\n",
       "  ('recently', 1),\n",
       "  ('regularity', 1),\n",
       "  ('release', 1),\n",
       "  ('relinquish', 1),\n",
       "  ('reluctant', 1),\n",
       "  ('reluntantly', 1),\n",
       "  ('rest', 1),\n",
       "  ('return', 1),\n",
       "  ('returning', 1),\n",
       "  ('returns', 4),\n",
       "  ('reveal', 1),\n",
       "  ('revenge', 1),\n",
       "  ('reviving', 1),\n",
       "  ('riding', 2),\n",
       "  ('righi', 1),\n",
       "  ('rika', 1),\n",
       "  ('ring', 3),\n",
       "  ('rises', 1),\n",
       "  ('room', 1),\n",
       "  ('rosy', 13),\n",
       "  ('rosys', 1),\n",
       "  ('ruins', 1),\n",
       "  ('run', 1),\n",
       "  ('runs', 1),\n",
       "  ('rural', 1),\n",
       "  ('rushes', 1),\n",
       "  ('russia', 1),\n",
       "  ('scene', 3),\n",
       "  ('screams', 1),\n",
       "  ('sdenka', 7),\n",
       "  ('seconds', 1),\n",
       "  ('seen', 1),\n",
       "  ('sees', 1),\n",
       "  ('segment', 1),\n",
       "  ('segments', 1),\n",
       "  ('seizes', 1),\n",
       "  ('series', 1),\n",
       "  ('several', 1),\n",
       "  ('shelter', 1),\n",
       "  ('show', 1),\n",
       "  ('siblings', 1),\n",
       "  ('sign', 1),\n",
       "  ('simple', 1),\n",
       "  ('simulate', 1),\n",
       "  ('sister', 1),\n",
       "  ('sitting', 1),\n",
       "  ('sleeps', 2),\n",
       "  ('slowly', 1),\n",
       "  ('small', 3),\n",
       "  ('solace', 1),\n",
       "  ('someone', 1),\n",
       "  ('son', 2),\n",
       "  ('soon', 2),\n",
       "  ('sound', 2),\n",
       "  ('sounds', 1),\n",
       "  ('sour', 1),\n",
       "  ('souvenir', 1),\n",
       "  ('space', 1),\n",
       "  ('spacious', 1),\n",
       "  ('splash', 1),\n",
       "  ('stabbing', 1),\n",
       "  ('stabs', 1),\n",
       "  ('stakes', 1),\n",
       "  ('stay', 2),\n",
       "  ('steals', 1),\n",
       "  ('stockings', 1),\n",
       "  ('stop', 1),\n",
       "  ('stops', 1),\n",
       "  ('strange', 3),\n",
       "  ('strangle', 1),\n",
       "  ('strangles', 2),\n",
       "  ('stroke', 1),\n",
       "  ('strong', 1),\n",
       "  ('struck', 1),\n",
       "  ('struggle', 1),\n",
       "  ('subsequently', 2),\n",
       "  ('suggestion', 1),\n",
       "  ('suicide', 1),\n",
       "  ('suite', 1),\n",
       "  ('supernatural', 1),\n",
       "  ('surprised', 1),\n",
       "  ('surrounded', 1),\n",
       "  ('susy', 1),\n",
       "  ('swooping', 1),\n",
       "  ('synopsis', 1),\n",
       "  ('taken', 2),\n",
       "  ('takes', 1),\n",
       "  ('taking', 1),\n",
       "  ('tales', 2),\n",
       "  ('telephonerosy', 1),\n",
       "  ('tells', 1),\n",
       "  ('tempted', 1),\n",
       "  ('term', 1),\n",
       "  ('terrified', 2),\n",
       "  ('testimony', 1),\n",
       "  ('threatens', 1),\n",
       "  ('three', 3),\n",
       "  ('throat', 1),\n",
       "  ('ties', 1),\n",
       "  ('time', 2),\n",
       "  ('tips', 1),\n",
       "  ('took', 1),\n",
       "  ('torn', 1),\n",
       "  ('towards', 1),\n",
       "  ('tranquillizer', 1),\n",
       "  ('transpires', 1),\n",
       "  ('trip', 1),\n",
       "  ('two', 3),\n",
       "  ('ultimately', 1),\n",
       "  ('unkempt', 1),\n",
       "  ('unknown', 1),\n",
       "  ('unsettled', 1),\n",
       "  ('urfe', 1),\n",
       "  ('vacant', 1),\n",
       "  ('vampires', 1),\n",
       "  ('various', 1),\n",
       "  ('victorian', 1),\n",
       "  ('viewers', 1),\n",
       "  ('violence', 1),\n",
       "  ('visible', 1),\n",
       "  ('vladimir', 10),\n",
       "  ('walking', 2),\n",
       "  ('walls', 1),\n",
       "  ('warn', 1),\n",
       "  ('water', 2),\n",
       "  ('waterin', 1),\n",
       "  ('way', 2),\n",
       "  ('well', 1),\n",
       "  ('white', 1),\n",
       "  ('wife', 2),\n",
       "  ('withdraws', 1),\n",
       "  ('without', 1),\n",
       "  ('woman', 3),\n",
       "  ('womans', 1),\n",
       "  ('women', 1),\n",
       "  ('worse', 1),\n",
       "  ('would', 1),\n",
       "  ('writing', 1),\n",
       "  ('wrong', 1),\n",
       "  ('wurdalak', 4),\n",
       "  ('wurdalakin', 1),\n",
       "  ('young', 4),\n",
       "  ('younger', 1)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "dl325HrLovVI",
    "outputId": "12b72290-5b0b-44cd-bf93-0579ac78b96a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install --upgrade gensim\\n\\n\\n#----------------------------step-2---------------------------------------------------------\\n\\nimport os       #importing os to set environment variable\\ndef install_java():\\n  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\\n  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\\n  !java -version       #check java version\\ninstall_java()\\n\\n\\n#----------------------------step-3----------------------------------------------------------\\n#below command directly download mallet zip file  into colab disk next line is we can unzip it and use that path to mallet \\n\\n!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\\n!unzip mallet-2.0.8.zip\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to run below steps before giving path to mallet because colab cannot access mallet from drive so we \n",
    "#need to upload entire mallet files here and also upgrade the gensim and install java for mallet \n",
    "\n",
    "#---------------------------step-1-------------------------------------------------------- -\n",
    "'''\n",
    "!pip install --upgrade gensim\n",
    "\n",
    "\n",
    "#----------------------------step-2---------------------------------------------------------\n",
    "\n",
    "import os       #importing os to set environment variable\n",
    "def install_java():\n",
    "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
    "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
    "  !java -version       #check java version\n",
    "install_java()\n",
    "\n",
    "\n",
    "#----------------------------step-3----------------------------------------------------------\n",
    "#below command directly download mallet zip file  into colab disk next line is we can unzip it and use that path to mallet \n",
    "\n",
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "!unzip mallet-2.0.8.zip\n",
    "'''\n",
    "#refer this https://github.com/polsci/colab-gensim-mallet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzWPkyb1mbwM"
   },
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/content/mallet-2.0.8/bin/mallet' # update this path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B9hBYvTmb3O"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrBKutWKmb71"
   },
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                        texts=pure_df['pre_pro_plot_synopsis_words'],\n",
    "                                                        start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "id": "Tsf2ObQ_mcAA",
    "outputId": "084f99f1-c566-47c5-9a9c-ebe44d0c0848"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.302\n",
      "Num Topics = 8  has Coherence Value of 0.378\n",
      "Num Topics = 14  has Coherence Value of 0.3894\n",
      "Num Topics = 20  has Coherence Value of 0.3903\n",
      "Num Topics = 26  has Coherence Value of 0.3858\n",
      "Num Topics = 32  has Coherence Value of 0.3786\n",
      "Num Topics = 38  has Coherence Value of 0.3802\n"
     ]
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaF3caucLjw_"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word,num_topics=20,random_state=100,update_every=1,chunksize=100,passes=10,alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xP-yR7WsjtOE",
    "outputId": "27a8df32-4fe2-4fa9-f489-cc1dd1365329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.009*\"earth\" + 0.009*\"ship\" + 0.008*\"world\" + 0.006*\"island\" + 0.006*\"crew\" + 0.005*\"betty\" + 0.005*\"dr\" + 0.005*\"control\" + 0.005*\"city\" + 0.005*\"human\"'), (1, '0.007*\"king\" + 0.006*\"fight\" + 0.005*\"one\" + 0.005*\"death\" + 0.005*\"kill\" + 0.004*\"however\" + 0.004*\"help\" + 0.003*\"two\" + 0.003*\"queen\" + 0.003*\"battle\"'), (2, '0.066*\"charlie\" + 0.044*\"joe\" + 0.038*\"frank\" + 0.029*\"helen\" + 0.021*\"jeff\" + 0.020*\"kit\" + 0.017*\"emma\" + 0.017*\"c\" + 0.015*\"n\" + 0.015*\"nina\"'), (3, '0.012*\"war\" + 0.007*\"men\" + 0.006*\"army\" + 0.006*\"soldiers\" + 0.006*\"american\" + 0.005*\"british\" + 0.005*\"captain\" + 0.005*\"group\" + 0.005*\"german\" + 0.005*\"general\"'), (4, '0.025*\"eric\" + 0.022*\"matt\" + 0.021*\"casey\" + 0.021*\"arthur\" + 0.018*\"jenny\" + 0.015*\"zombies\" + 0.014*\"ogami\" + 0.013*\"godfrey\" + 0.012*\"wolf\" + 0.011*\"vera\"'), (5, '0.045*\"george\" + 0.034*\"jerry\" + 0.025*\"chris\" + 0.024*\"bugs\" + 0.017*\"roy\" + 0.016*\"kate\" + 0.015*\"anna\" + 0.014*\"logan\" + 0.011*\"joanna\" + 0.011*\"jonathan\"'), (6, '0.022*\"max\" + 0.021*\"johnny\" + 0.016*\"adam\" + 0.014*\"ghost\" + 0.013*\"daniel\" + 0.011*\"witch\" + 0.010*\"white\" + 0.009*\"devil\" + 0.008*\"god\" + 0.008*\"monster\"'), (7, '0.015*\"prison\" + 0.010*\"nick\" + 0.010*\"bernard\" + 0.009*\"charles\" + 0.009*\"dant\" + 0.008*\"wilson\" + 0.007*\"count\" + 0.007*\"philip\" + 0.006*\"judge\" + 0.006*\"sherman\"'), (8, '0.034*\"john\" + 0.018*\"david\" + 0.012*\"doctor\" + 0.012*\"richard\" + 0.010*\"sarah\" + 0.010*\"robert\" + 0.009*\"dr\" + 0.009*\"ann\" + 0.007*\"elizabeth\" + 0.006*\"william\"'), (9, '0.038*\"mr\" + 0.035*\"henry\" + 0.024*\"sir\" + 0.023*\"mrs\" + 0.023*\"rachel\" + 0.022*\"jane\" + 0.016*\"brown\" + 0.015*\"barbara\" + 0.015*\"batman\" + 0.014*\"bruce\"'), (10, '0.018*\"police\" + 0.011*\"jack\" + 0.009*\"money\" + 0.008*\"kill\" + 0.008*\"killed\" + 0.007*\"car\" + 0.007*\"sam\" + 0.007*\"gang\" + 0.006*\"man\" + 0.005*\"murder\"'), (11, '0.010*\"valjean\" + 0.007*\"goku\" + 0.007*\"son\" + 0.006*\"om\" + 0.006*\"kishen\" + 0.006*\"jin\" + 0.005*\"th\" + 0.005*\"gauri\" + 0.005*\"ajay\" + 0.005*\"india\"'), (12, '0.014*\"house\" + 0.008*\"find\" + 0.008*\"back\" + 0.008*\"finds\" + 0.007*\"body\" + 0.007*\"car\" + 0.007*\"room\" + 0.007*\"man\" + 0.005*\"night\" + 0.005*\"dead\"'), (13, '0.042*\"michael\" + 0.024*\"tommy\" + 0.019*\"steve\" + 0.017*\"todd\" + 0.016*\"tony\" + 0.013*\"leo\" + 0.012*\"anne\" + 0.011*\"albert\" + 0.009*\"el\" + 0.009*\"frankie\"'), (14, '0.031*\"not\" + 0.023*\"tells\" + 0.014*\"back\" + 0.012*\"get\" + 0.011*\"asks\" + 0.011*\"go\" + 0.010*\"tom\" + 0.010*\"goes\" + 0.010*\"says\" + 0.008*\"gets\"'), (15, '0.012*\"school\" + 0.008*\"new\" + 0.006*\"bill\" + 0.006*\"show\" + 0.005*\"game\" + 0.005*\"jimmy\" + 0.004*\"friends\" + 0.004*\"fred\" + 0.004*\"high\" + 0.004*\"jason\"'), (16, '0.028*\"town\" + 0.013*\"men\" + 0.012*\"ben\" + 0.011*\"billy\" + 0.010*\"sheriff\" + 0.008*\"jean\" + 0.008*\"horse\" + 0.008*\"gold\" + 0.007*\"hamlet\" + 0.007*\"joseph\"'), (17, '0.029*\"paul\" + 0.024*\"harry\" + 0.024*\"alice\" + 0.019*\"alex\" + 0.019*\"lucy\" + 0.015*\"maria\" + 0.014*\"amy\" + 0.013*\"edward\" + 0.011*\"marie\" + 0.010*\"arisen\"'), (18, '0.028*\"jim\" + 0.028*\"peter\" + 0.016*\"scott\" + 0.015*\"red\" + 0.010*\"cat\" + 0.010*\"spider\" + 0.009*\"gus\" + 0.009*\"bart\" + 0.008*\"silver\" + 0.007*\"porky\"'), (19, '0.011*\"father\" + 0.010*\"not\" + 0.008*\"family\" + 0.008*\"mother\" + 0.008*\"love\" + 0.007*\"one\" + 0.007*\"life\" + 0.006*\"home\" + 0.006*\"time\" + 0.006*\"film\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "print(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n",
    "data = pure_df['pre_pro_plot_synopsis'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rY0JNddhJy7n",
    "outputId": "60b31d68-3b9c-4a33-f729-dc19b1e56e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 59s, sys: 3min 19s, total: 13min 19s\n",
      "Wall time: 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list  in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AkZqUzvvSX-E"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv('drive/My Drive/colab/topic_modelling_data.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUnIH0imYsQC"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic =  pd.read_csv('topic_modelling_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "fA0P0fYrSzzy",
    "outputId": "c9b82b82-75e1-4ebc-fa9f-1c055bdc247a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>tags_count</th>\n",
       "      <th>tags_2</th>\n",
       "      <th>pre_pro_title</th>\n",
       "      <th>pre_pro_plot_synopsis</th>\n",
       "      <th>pre_pro_tags</th>\n",
       "      <th>pre_pro_plot_synopsis_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>5</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>tre volti della paura</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>[note, synopsis, orginal, italian, release, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>violence</td>\n",
       "      <td>dungeons dragons book vile darkness</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "      <td>violence</td>\n",
       "      <td>[two, thousand, years, ago, nhagruul, foul, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>romantic</td>\n",
       "      <td>shop around corner</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>[matuschek, gift, store, budapest, workplace, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    imdb_id                                          title  \\\n",
       "0           0  tt0057603                        I tre volti della paura   \n",
       "1           1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2           2  tt0033045                     The Shop Around the Corner   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "\n",
       "                                        tags  split synopsis_source  \\\n",
       "0  cult, horror, gothic, murder, atmospheric  train            imdb   \n",
       "1                                   violence  train            imdb   \n",
       "2                                   romantic   test            imdb   \n",
       "\n",
       "   tags_count                                 tags_2  \\\n",
       "0           5  cult horror gothic murder atmospheric   \n",
       "1           1                               violence   \n",
       "2           1                               romantic   \n",
       "\n",
       "                         pre_pro_title  \\\n",
       "0                tre volti della paura   \n",
       "1  dungeons dragons book vile darkness   \n",
       "2                   shop around corner   \n",
       "\n",
       "                               pre_pro_plot_synopsis  \\\n",
       "0  note synopsis orginal italian release segments...   \n",
       "1  two thousand years ago nhagruul foul sorcerer ...   \n",
       "2  matuschek gift store budapest workplace alfred...   \n",
       "\n",
       "                            pre_pro_tags  \\\n",
       "0  cult horror gothic murder atmospheric   \n",
       "1                               violence   \n",
       "2                               romantic   \n",
       "\n",
       "                         pre_pro_plot_synopsis_words  \n",
       "0  [note, synopsis, orginal, italian, release, se...  \n",
       "1  [two, thousand, years, ago, nhagruul, foul, so...  \n",
       "2  [matuschek, gift, store, budapest, workplace, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "DAZy-JUZSYEp",
    "outputId": "ab0d28d3-6e15-44a3-8b4e-ad48d4e479eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>house, find, back, finds, body, car, room, man...</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>king, fight, one, death, kill, however, help, ...</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>father, not, family, mother, love, one, life, ...</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            12.0              0.2685   \n",
       "1            1             1.0              0.3064   \n",
       "2            2            19.0              0.3600   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  house, find, back, finds, body, car, room, man...   \n",
       "1  king, fight, one, death, kill, however, help, ...   \n",
       "2  father, not, family, mother, love, one, life, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  note synopsis orginal italian release segments...  \n",
       "1  two thousand years ago nhagruul foul sorcerer ...  \n",
       "2  matuschek gift store budapest workplace alfred...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "CKKyszyVSYJB",
    "outputId": "d67a23f6-ac66-4c09-db0a-aecbeeca03bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>tags_count</th>\n",
       "      <th>tags_2</th>\n",
       "      <th>pre_pro_title</th>\n",
       "      <th>pre_pro_plot_synopsis</th>\n",
       "      <th>pre_pro_tags</th>\n",
       "      <th>pre_pro_plot_synopsis_words</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>5</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>tre volti della paura</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>[note, synopsis, orginal, italian, release, se...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>house, find, back, finds, body, car, room, man...</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>violence</td>\n",
       "      <td>dungeons dragons book vile darkness</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "      <td>violence</td>\n",
       "      <td>[two, thousand, years, ago, nhagruul, foul, so...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>king, fight, one, death, kill, however, help, ...</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>romantic</td>\n",
       "      <td>shop around corner</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>[matuschek, gift, store, budapest, workplace, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>father, not, family, mother, love, one, life, ...</td>\n",
       "      <td>matuschek gift store budapest workplace alfred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>4</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>mr holland opus</td>\n",
       "      <td>glenn holland not morning person anyone standa...</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>[glenn, holland, not, morning, person, anyone,...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3882</td>\n",
       "      <td>father, not, family, mother, love, one, life, ...</td>\n",
       "      <td>glenn holland not morning person anyone standa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>imdb</td>\n",
       "      <td>10</td>\n",
       "      <td>cruelty murder dramatic cult violence atmosphe...</td>\n",
       "      <td>scarface</td>\n",
       "      <td>may 1980 cuban man named tony montana al pacin...</td>\n",
       "      <td>cruelty murder dramatic cult violence atmosphe...</td>\n",
       "      <td>[may, 1980, cuban, man, named, tony, montana, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2406</td>\n",
       "      <td>police, jack, money, kill, killed, car, sam, g...</td>\n",
       "      <td>may 1980 cuban man named tony montana al pacin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    imdb_id                                          title  \\\n",
       "0           0  tt0057603                        I tre volti della paura   \n",
       "1           1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2           2  tt0033045                     The Shop Around the Corner   \n",
       "3           3  tt0113862                             Mr. Holland's Opus   \n",
       "4           4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split synopsis_source  \\\n",
       "0          cult, horror, gothic, murder, atmospheric  train            imdb   \n",
       "1                                           violence  train            imdb   \n",
       "2                                           romantic   test            imdb   \n",
       "3             inspiring, romantic, stupid, feel-good  train            imdb   \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val            imdb   \n",
       "\n",
       "   tags_count                                             tags_2  \\\n",
       "0           5              cult horror gothic murder atmospheric   \n",
       "1           1                                           violence   \n",
       "2           1                                           romantic   \n",
       "3           4                inspiring romantic stupid feel-good   \n",
       "4          10  cruelty murder dramatic cult violence atmosphe...   \n",
       "\n",
       "                         pre_pro_title  \\\n",
       "0                tre volti della paura   \n",
       "1  dungeons dragons book vile darkness   \n",
       "2                   shop around corner   \n",
       "3                      mr holland opus   \n",
       "4                             scarface   \n",
       "\n",
       "                               pre_pro_plot_synopsis  \\\n",
       "0  note synopsis orginal italian release segments...   \n",
       "1  two thousand years ago nhagruul foul sorcerer ...   \n",
       "2  matuschek gift store budapest workplace alfred...   \n",
       "3  glenn holland not morning person anyone standa...   \n",
       "4  may 1980 cuban man named tony montana al pacin...   \n",
       "\n",
       "                                        pre_pro_tags  \\\n",
       "0              cult horror gothic murder atmospheric   \n",
       "1                                           violence   \n",
       "2                                           romantic   \n",
       "3                inspiring romantic stupid feel-good   \n",
       "4  cruelty murder dramatic cult violence atmosphe...   \n",
       "\n",
       "                         pre_pro_plot_synopsis_words  Document_No  \\\n",
       "0  [note, synopsis, orginal, italian, release, se...            0   \n",
       "1  [two, thousand, years, ago, nhagruul, foul, so...            1   \n",
       "2  [matuschek, gift, store, budapest, workplace, ...            2   \n",
       "3  [glenn, holland, not, morning, person, anyone,...            3   \n",
       "4  [may, 1980, cuban, man, named, tony, montana, ...            4   \n",
       "\n",
       "   Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            12.0              0.2685   \n",
       "1             1.0              0.3064   \n",
       "2            19.0              0.3600   \n",
       "3            19.0              0.3882   \n",
       "4            10.0              0.2406   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  house, find, back, finds, body, car, room, man...   \n",
       "1  king, fight, one, death, kill, however, help, ...   \n",
       "2  father, not, family, mother, love, one, life, ...   \n",
       "3  father, not, family, mother, love, one, life, ...   \n",
       "4  police, jack, money, kill, killed, car, sam, g...   \n",
       "\n",
       "                                                Text  \n",
       "0  note synopsis orginal italian release segments...  \n",
       "1  two thousand years ago nhagruul foul sorcerer ...  \n",
       "2  matuschek gift store budapest workplace alfred...  \n",
       "3  glenn holland not morning person anyone standa...  \n",
       "4  may 1980 cuban man named tony montana al pacin...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model=pd.concat([pure_df,df_dominant_topic], axis=1)\n",
    "final_model.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "a1YTAqyoY5jA",
    "outputId": "d158a1f9-2eec-4355-d8dd-a679087dc6cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape (9435, 17) (9435, 71)\n",
      "train_data shape (2362, 17) (2362, 71)\n",
      "test_data shape (2955, 17) (2955, 71)\n"
     ]
    }
   ],
   "source": [
    "x_train = final_model.loc[(final_model['split'] == 'train')]\n",
    "x_cv = final_model.loc[(final_model['split'] == 'val')]\n",
    "x_test = final_model.loc[(final_model['split'] == 'test')]\n",
    "\n",
    "y_train_71 = x_train['pre_pro_tags']\n",
    "y_cv_71 = x_cv['pre_pro_tags']\n",
    "y_test_71 = x_test['pre_pro_tags']\n",
    "\n",
    "\n",
    "#Convert the tags to binary vectors\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\" \"), binary='true')\n",
    "y_train_71 = vectorizer.fit_transform(y_train_71)\n",
    "y_cv_71 = vectorizer.transform(y_cv_71)\n",
    "y_test_71 = vectorizer.transform(y_test_71)\n",
    "\n",
    "print('train_data shape',x_train.shape,y_train_71.shape)\n",
    "print('train_data shape',x_cv.shape,y_cv_71.shape)\n",
    "print('test_data shape',x_test.shape,y_test_71.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fr9nUmE5I62"
   },
   "source": [
    "<h3>Bow</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pJ7OOBF_Y9ME",
    "outputId": "2ec91fd1-e619-47af-ae4b-892bac7312f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.9 s, sys: 19 ms, total: 5.92 s\n",
      "Wall time: 5.93 s\n"
     ]
    }
   ],
   "source": [
    "#plots + topics \n",
    "#plots\n",
    "%%time\n",
    "vectorizer = CountVectorizer(min_df=10)\n",
    "xb_train_multilabel = vectorizer.fit_transform(x_train['pre_pro_plot_synopsis'])\n",
    "xb_cv_multilabel = vectorizer.transform(x_cv['pre_pro_plot_synopsis'])\n",
    "xb_test_multilabel = vectorizer.transform(x_test['pre_pro_plot_synopsis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2zc70pmjdgA_",
    "outputId": "82aa4475-91d0-4616-e160-8286867b630a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 0 ns, total: 170 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "#topics\n",
    "%%time\n",
    "vectorizer = CountVectorizer(min_df=10)\n",
    "xk_train_multilabel = vectorizer.fit_transform(x_train['Keywords'])\n",
    "xk_cv_multilabel = vectorizer.transform(x_cv['Keywords'])\n",
    "xk_test_multilabel = vectorizer.transform(x_test['Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2kCfMTxVeiWh",
    "outputId": "3c8356e3-6dbc-42ec-e56e-9fe05bbd388e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow_train data (9435, 21404) (9435, 71)\n",
      "bow_cv data (2362, 21404) (2362, 71)\n",
      "bow_test data (2955, 21404) (2955, 71)\n"
     ]
    }
   ],
   "source": [
    "#topics + plots \n",
    "from scipy.sparse import hstack\n",
    "xb_topic_plot_train=hstack([xb_train_multilabel,xk_train_multilabel])\n",
    "xb_topic_plot_cv=hstack([xb_cv_multilabel,xk_cv_multilabel])\n",
    "xb_topic_plot_test=hstack([xb_test_multilabel,xk_test_multilabel])\n",
    "\n",
    "print('bow_train data',xb_topic_plot_train.shape,y_train_71.shape)\n",
    "print('bow_cv data',xb_topic_plot_cv.shape,y_cv_71.shape)\n",
    "print('bow_test data',xb_topic_plot_test.shape,y_test_71.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Tzt2uJgeuQs"
   },
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "#we have multiple models to train so we create a model function \n",
    "def log_reg(x_train,y_train,x_cv,y_cv,x_test,y_test):\n",
    "  train_f1 = []\n",
    "  cv_f1 = []\n",
    "  parameters=[0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
    "  for i in parameters:\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(C=i, penalty='l1',class_weight='balanced'))\n",
    "    classifier.fit(x_train, y_train)\n",
    "    train_predictions = classifier.predict (x_train)\n",
    "    train_f1_score = f1_score(y_train, train_predictions, average='micro')\n",
    "    train_f1.append(train_f1_score)\n",
    "    cv_predictions = classifier.predict(x_cv)\n",
    "    cv_f1_score = f1_score(y_cv, cv_predictions, average='micro')\n",
    "    cv_f1.append(cv_f1_score)\n",
    "    print(\"for\",i,      \"Train_f1_score: {:.4f}, Cv_f1_score: {:.4f}\".format(train_f1_score, cv_f1_score))\n",
    "  best_estimators = np.argmax(cv_f1)\n",
    "  print('best parameter :',parameters[best_estimators])\n",
    "  #modeling with test data with best hyper paremeter \n",
    "  classifier2 = OneVsRestClassifier(LogisticRegression(C=parameters[best_estimators], penalty='l1',class_weight='balanced'))\n",
    "  classifier2.fit(x_train, y_train)\n",
    "  predictions = classifier2.predict(x_test)\n",
    "\n",
    "  print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "  print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "  precision = precision_score(y_test, predictions, average='micro')\n",
    "  recall = recall_score(y_test, predictions, average='micro')\n",
    "  f1 = f1_score(y_test, predictions, average='micro')\n",
    "  \n",
    "  print(\"Micro-average :\") \n",
    "  print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "aNaZJRb85fCj",
    "outputId": "a89b8d03-fda7-4603-88ee-8ba893ab2ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 0.0001 Train_f1_score: 0.0061, Cv_f1_score: 0.0072\n",
      "for 0.001 Train_f1_score: 0.1159, Cv_f1_score: 0.1172\n",
      "for 0.01 Train_f1_score: 0.3814, Cv_f1_score: 0.2866\n",
      "for 0.1 Train_f1_score: 0.7747, Cv_f1_score: 0.3188\n",
      "for 1 Train_f1_score: 0.9723, Cv_f1_score: 0.2987\n",
      "for 10 Train_f1_score: 0.9731, Cv_f1_score: 0.2906\n",
      "for 100 Train_f1_score: 0.9731, Cv_f1_score: 0.2896\n",
      "for 1000 Train_f1_score: 0.9731, Cv_f1_score: 0.2825\n",
      "best parameter : 0.1\n",
      "Accuracy : 0.028764805414551606\n",
      "Hamming loss  0.06989347251018803\n",
      "Micro-average :\n",
      "Precision: 0.2763, Recall: 0.3878, F1-measure: 0.3227\n"
     ]
    }
   ],
   "source": [
    "log_reg(xb_topic_plot_train,y_train_71,xb_topic_plot_cv,y_cv_71,xb_topic_plot_test,y_test_71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgK4EjyceQmf"
   },
   "source": [
    "<h3> TF IDF </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "teXtyUKki-sf",
    "outputId": "728de7ee-c13b-43d4-e3af-4e35c264bd84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.39 s, sys: 22.1 ms, total: 6.41 s\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "#plots + topics \n",
    "#plots\n",
    "%%time\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "xt_train_multilabel = vectorizer.fit_transform(x_train['pre_pro_plot_synopsis'])\n",
    "xt_cv_multilabel = vectorizer.transform(x_cv['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer.transform(x_test['pre_pro_plot_synopsis'])\n",
    "\n",
    "#topics\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "xtk_train_multilabel = vectorizer.fit_transform(x_train['Keywords'])\n",
    "xtk_cv_multilabel = vectorizer.transform(x_cv['Keywords'])\n",
    "xtk_test_multilabel = vectorizer.transform(x_test['Keywords'])\n",
    "\n",
    "#topics + plots \n",
    "xt_topic_plot_train=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "xt_topic_plot_cv=hstack([xt_cv_multilabel,xtk_cv_multilabel])\n",
    "xt_topic_plot_test=hstack([xt_test_multilabel,xtk_test_multilabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "tlDHlRvMn9QT",
    "outputId": "0cbc3a68-5162-45a9-920b-adaea986d28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 0.0001 Train_f1_score: 0.0000, Cv_f1_score: 0.0000\n",
      "for 0.001 Train_f1_score: 0.0000, Cv_f1_score: 0.0000\n",
      "for 0.01 Train_f1_score: 0.1168, Cv_f1_score: 0.1240\n",
      "for 0.1 Train_f1_score: 0.1956, Cv_f1_score: 0.1817\n",
      "for 1 Train_f1_score: 0.5446, Cv_f1_score: 0.3103\n",
      "for 10 Train_f1_score: 0.9355, Cv_f1_score: 0.3012\n",
      "for 100 Train_f1_score: 0.9730, Cv_f1_score: 0.2911\n",
      "for 1000 Train_f1_score: 0.9731, Cv_f1_score: 0.2885\n",
      "best parameter : 1\n",
      "Accuracy : 0.013874788494077835\n",
      "Hamming loss  0.08743356926670003\n",
      "Micro-average :\n",
      "Precision: 0.2349, Recall: 0.4591, F1-measure: 0.3108\n"
     ]
    }
   ],
   "source": [
    "log_reg(xt_topic_plot_train,y_train_71,xt_topic_plot_cv,y_cv_71,xt_topic_plot_test,y_test_71) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCppLBY8nkQv"
   },
   "source": [
    "<h2> Tuning Parameters with GridSearch using TFIDF </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V0qW7pRknuId",
    "outputId": "f644a57d-44ac-4466-c16e-f2ad98f174d1"
   },
   "outputs": [],
   "source": [
    "train_data  = final_model.loc[(final_model['split'] == 'train') | (final_model['split'] == 'val')]\n",
    "test_data = final_model.loc[(final_model['split'] == 'test')]\n",
    "y_train = train_data['pre_pro_tags']\n",
    "y_test = test_data['pre_pro_tags']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "_mlr3mJovn-a",
    "outputId": "9c62d9b7-6172-4869-d8ad-b8a3019c0167"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>tags_count</th>\n",
       "      <th>tags_2</th>\n",
       "      <th>pre_pro_title</th>\n",
       "      <th>pre_pro_plot_synopsis</th>\n",
       "      <th>pre_pro_tags</th>\n",
       "      <th>pre_pro_plot_synopsis_words</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>5</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>tre volti della paura</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "      <td>cult horror gothic murder atmospheric</td>\n",
       "      <td>[note, synopsis, orginal, italian, release, se...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>house, find, back, finds, body, car, room, man...</td>\n",
       "      <td>note synopsis orginal italian release segments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>violence</td>\n",
       "      <td>dungeons dragons book vile darkness</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "      <td>violence</td>\n",
       "      <td>[two, thousand, years, ago, nhagruul, foul, so...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>king, fight, one, death, kill, however, help, ...</td>\n",
       "      <td>two thousand years ago nhagruul foul sorcerer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>imdb</td>\n",
       "      <td>4</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>mr holland opus</td>\n",
       "      <td>glenn holland not morning person anyone standa...</td>\n",
       "      <td>inspiring romantic stupid feel-good</td>\n",
       "      <td>[glenn, holland, not, morning, person, anyone,...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3882</td>\n",
       "      <td>father, not, family, mother, love, one, life, ...</td>\n",
       "      <td>glenn holland not morning person anyone standa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    imdb_id                                          title  \\\n",
       "0           0  tt0057603                        I tre volti della paura   \n",
       "1           1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "3           3  tt0113862                             Mr. Holland's Opus   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "\n",
       "                                        tags  split synopsis_source  \\\n",
       "0  cult, horror, gothic, murder, atmospheric  train            imdb   \n",
       "1                                   violence  train            imdb   \n",
       "3     inspiring, romantic, stupid, feel-good  train            imdb   \n",
       "\n",
       "   tags_count                                 tags_2  \\\n",
       "0           5  cult horror gothic murder atmospheric   \n",
       "1           1                               violence   \n",
       "3           4    inspiring romantic stupid feel-good   \n",
       "\n",
       "                         pre_pro_title  \\\n",
       "0                tre volti della paura   \n",
       "1  dungeons dragons book vile darkness   \n",
       "3                      mr holland opus   \n",
       "\n",
       "                               pre_pro_plot_synopsis  \\\n",
       "0  note synopsis orginal italian release segments...   \n",
       "1  two thousand years ago nhagruul foul sorcerer ...   \n",
       "3  glenn holland not morning person anyone standa...   \n",
       "\n",
       "                            pre_pro_tags  \\\n",
       "0  cult horror gothic murder atmospheric   \n",
       "1                               violence   \n",
       "3    inspiring romantic stupid feel-good   \n",
       "\n",
       "                         pre_pro_plot_synopsis_words  Document_No  \\\n",
       "0  [note, synopsis, orginal, italian, release, se...            0   \n",
       "1  [two, thousand, years, ago, nhagruul, foul, so...            1   \n",
       "3  [glenn, holland, not, morning, person, anyone,...            3   \n",
       "\n",
       "   Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            12.0              0.2685   \n",
       "1             1.0              0.3064   \n",
       "3            19.0              0.3882   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  house, find, back, finds, body, car, room, man...   \n",
       "1  king, fight, one, death, kill, however, help, ...   \n",
       "3  father, not, family, mother, love, one, life, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  note synopsis orginal italian release segments...  \n",
       "1  two thousand years ago nhagruul foul sorcerer ...  \n",
       "3  glenn holland not morning person anyone standa...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EzftiV4unuOm",
    "outputId": "a1ab58c6-4033-48af-f94a-0b89e2fa20cb"
   },
   "outputs": [],
   "source": [
    "#Computing Grid/Random search is computational expensive on BOW Vectorizer so we trying on TFIDF accoring to research paper \n",
    "#TFIDF UNI GRAMS\n",
    "#plots + keywords \n",
    "#keywords\n",
    "\n",
    "vectorizer_1 = TfidfVectorizer(min_df=0.00009,max_features=100000, smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False,\n",
    "                             ngram_range=(1,1))\n",
    "xt_train_multilabel = vectorizer_1.fit_transform(train_data['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer_1.transform(test_data['pre_pro_plot_synopsis'])\n",
    "\n",
    "\n",
    "#topics\n",
    "vectorizer_2 = TfidfVectorizer(smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False,\n",
    "                             ngram_range=(1,1))\n",
    "xtk_train_multilabel = vectorizer_2.fit_transform(train_data['Keywords'])\n",
    "xtk_test_multilabel = vectorizer_2.transform(test_data['Keywords'])\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\" \"), binary='true').fit(y_train)\n",
    "y_train = vectorizer.transform(y_train)\n",
    "y_test = vectorizer.transform(y_test)\n",
    "\n",
    "\n",
    "#topics + plots \n",
    "xt_topic_plot_train=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "xt_topic_plot_test=hstack([xt_test_multilabel,xtk_test_multilabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "qfdjb9rrnuS5",
    "outputId": "a221c878-741f-40fb-fefe-f9cb7243783c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed: 18.9min remaining:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 24.2min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 24.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False),\n",
      "                    n_jobs=-1)\n",
      "Best Cross Validation Score:  0.33367728723098383\n",
      "Accuracy : 0.029441624365482234\n",
      "Hamming loss  0.06874002049522175\n",
      "Micro-average :\n",
      "Precision: 0.2925, Recall: 0.4235, F1-measure: 0.3460\n"
     ]
    }
   ],
   "source": [
    "#Randomsearch_Cv using Logisitic regression \n",
    "alpha = [0.001,0.01,0.1,0.5,0.9,1,1.5,10,100,1000]\n",
    "penalty = ['l1','l2']\n",
    "\n",
    "params  = {'estimator__C': alpha,\n",
    "          'estimator__penalty': penalty}\n",
    "clf_estimator = OneVsRestClassifier(LogisticRegression(class_weight='balanced'), n_jobs=-1)\n",
    "RS_clf = RandomizedSearchCV(estimator=clf_estimator, param_distributions=params, n_iter=10, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "RS_clf.fit(xt_topic_plot_train, y_train)\n",
    "print('Best estimator: ',RS_clf.best_estimator_)\n",
    "print('Best Cross Validation Score: ',RS_clf.best_score_) \n",
    "\n",
    "classifier2 = RS_clf.best_estimator_\n",
    "classifier2.fit(xt_topic_plot_train, y_train)\n",
    "predictions = classifier2.predict(xt_topic_plot_test)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average :\") \n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "apJTuXs8nuWy",
    "outputId": "ab15b444-6fe7-475b-824d-2e7e1593ea94",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed: 25.2min remaining:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 25.9min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 26.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False),\n",
      "                    n_jobs=-1)\n",
      "Best Cross Validation Score:  0.3406132820133223\n",
      "Accuracy : 0.031810490693739424\n",
      "Hamming loss  0.06645694811849098\n",
      "Micro-average :\n",
      "Precision: 0.3033, Recall: 0.4224, F1-measure: 0.3531\n"
     ]
    }
   ],
   "source": [
    "#Computing Grid/Random search is computational expensive on BOW Vectorizer so we trying on TFIDF accoring to research paper \n",
    "#TFIDF N GRAMS(1,2)\n",
    "#plots + keywords \n",
    "#keywords\n",
    "vectorizer_3 = TfidfVectorizer(min_df=0.00009,max_features=100000, smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False,\n",
    "                             ngram_range=(1,2))\n",
    "xt_train_multilabel = vectorizer_3.fit_transform(train_data['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer_3.transform(test_data['pre_pro_plot_synopsis'])\n",
    "\n",
    "#topics\n",
    "vectorizer_4 = TfidfVectorizer(smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False,\n",
    "                             ngram_range=(1,1))\n",
    "xtk_train_multilabel = vectorizer_4.fit_transform(train_data['Keywords'])\n",
    "xtk_test_multilabel = vectorizer_4.transform(test_data['Keywords'])\n",
    "\n",
    "#topics + plots \n",
    "\n",
    "xt_topic_plot_train=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "xt_topic_plot_test=hstack([xt_test_multilabel,xtk_test_multilabel])\n",
    "\n",
    "#Randomsearch_Cv using Logisitic regression \n",
    "alpha = [0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
    "penalty = ['l1','l2']\n",
    "\n",
    "params  = {'estimator__C': alpha,\n",
    "          'estimator__penalty': penalty}\n",
    "clf_estimator = OneVsRestClassifier(LogisticRegression(class_weight='balanced'), n_jobs=-1)\n",
    "RS_clf = RandomizedSearchCV(estimator=clf_estimator, param_distributions=params, n_iter=10, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "RS_clf.fit(xt_topic_plot_train, y_train)\n",
    "print('Best estimator: ',RS_clf.best_estimator_)\n",
    "print('Best Cross Validation Score: ',RS_clf.best_score_) \n",
    "\n",
    "classifier2 = RS_clf.best_estimator_\n",
    "classifier2.fit(xt_topic_plot_train, y_train)\n",
    "predictions = classifier2.predict(xt_topic_plot_test)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average :\") \n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "cHCA16BrVJi6",
    "outputId": "1ddbba24-04e2-4a73-c987-3a512602dc9e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed: 19.5min remaining:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 23.3min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 23.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False),\n",
      "                    n_jobs=-1)\n",
      "Best Cross Validation Score:  0.33779041496260004\n",
      "Accuracy : 0.028764805414551606\n",
      "Hamming loss  0.06827768642310716\n",
      "Micro-average :\n",
      "Precision: 0.2971, Recall: 0.4322, F1-measure: 0.3521\n"
     ]
    }
   ],
   "source": [
    "#Computing Grid/Random search is computational expensive on BOW Vectorizer so we trying on TFIDF accoring to research paper \n",
    "#TFIDF N GRAMS(1,3)\n",
    "#plots + keywords \n",
    "#keywords\n",
    "vectorizer_5 = TfidfVectorizer(min_df=0.00009,max_features=50000, smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False,\n",
    "                             ngram_range=(1,3))\n",
    "xt_train_multilabel = vectorizer_5.fit_transform(train_data['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer_5.transform(test_data['pre_pro_plot_synopsis'])\n",
    "\n",
    "#topics\n",
    "vectorizer_6 = TfidfVectorizer(smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False,\n",
    "                             ngram_range=(1,1))\n",
    "xtk_train_multilabel = vectorizer_6.fit_transform(train_data['Keywords'])\n",
    "xtk_test_multilabel = vectorizer_6.transform(test_data['Keywords'])\n",
    "\n",
    "#topics + plots \n",
    "xt_topic_plot_train=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "xt_topic_plot_test=hstack([xt_test_multilabel,xtk_test_multilabel])\n",
    "\n",
    "#Randomsearch_Cv using Logisitic regression \n",
    "alpha = [0.001,0.01,0.1,0.5,0.9,1,1.5,10,100,1000]\n",
    "penalty = ['l1','l2']\n",
    "\n",
    "params  = {'estimator__C': alpha,\n",
    "          'estimator__penalty': penalty}\n",
    "clf_estimator = OneVsRestClassifier(LogisticRegression(class_weight='balanced'), n_jobs=-1)\n",
    "RS_clf = RandomizedSearchCV(estimator=clf_estimator, param_distributions=params, n_iter=10, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "RS_clf.fit(xt_topic_plot_train, y_train)\n",
    "print('Best estimator: ',RS_clf.best_estimator_)\n",
    "print('Best Cross Validation Score: ',RS_clf.best_score_) \n",
    "\n",
    "classifier2 = RS_clf.best_estimator_\n",
    "classifier2.fit(xt_topic_plot_train, y_train)\n",
    "predictions = classifier2.predict(xt_topic_plot_test)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average :\") \n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing Grid/Random search is computational expensive on BOW Vectorizer so we trying on TFIDF accoring to research paper \n",
    "#TFIDF UNI GRAMS\n",
    "#plots + keywords \n",
    "#keywords\n",
    "\n",
    "vectorizer_1 = TfidfVectorizer(min_df=0.00009,max_features=10000,ngram_range=(1,1))\n",
    "xt_train_multilabel = vectorizer_1.fit_transform(train_data['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer_1.transform(test_data['pre_pro_plot_synopsis'])\n",
    "\n",
    "\n",
    "#topics\n",
    "vectorizer_2 = TfidfVectorizer(ngram_range=(1,1))\n",
    "xtk_train_multilabel = vectorizer_2.fit_transform(train_data['Keywords'])\n",
    "xtk_test_multilabel = vectorizer_2.transform(test_data['Keywords'])\n",
    "\n",
    "#topics + plots \n",
    "train_uni=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "test_uni=hstack([xt_test_multilabel,xtk_test_multilabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_3 = TfidfVectorizer(min_df=0.00009,max_features=10000,ngram_range=(1,2))\n",
    "xt_train_multilabel = vectorizer_3.fit_transform(train_data['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer_3.transform(test_data['pre_pro_plot_synopsis'])\n",
    "\n",
    "#topics\n",
    "vectorizer_4 = TfidfVectorizer(ngram_range=(1,1))\n",
    "xtk_train_multilabel = vectorizer_4.fit_transform(train_data['Keywords'])\n",
    "xtk_test_multilabel = vectorizer_4.transform(test_data['Keywords'])\n",
    "\n",
    "#topics + plots \n",
    "\n",
    "train_bi=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "test_bi=hstack([xt_test_multilabel,xtk_test_multilabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_5 = TfidfVectorizer(min_df=0.00009,max_features=10000,ngram_range=(1,3))\n",
    "xt_train_multilabel = vectorizer_5.fit_transform(train_data['pre_pro_plot_synopsis'])\n",
    "xt_test_multilabel = vectorizer_5.transform(test_data['pre_pro_plot_synopsis'])\n",
    "\n",
    "#topics\n",
    "vectorizer_6 = TfidfVectorizer(ngram_range=(1,1))\n",
    "xtk_train_multilabel = vectorizer_6.fit_transform(train_data['Keywords'])\n",
    "xtk_test_multilabel = vectorizer_6.transform(test_data['Keywords'])\n",
    "\n",
    "#topics + plots \n",
    "train_tri=hstack([xt_train_multilabel,xtk_train_multilabel])\n",
    "test_tri=hstack([xt_test_multilabel,xtk_test_multilabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uni + bi\n",
    "x_train_uni_bi = hstack([train_uni,train_bi])\n",
    "x_test_uni_bi = hstack([test_uni,test_bi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11797, 20380)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_uni_bi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uni + bi + tri \n",
    "x_train_uni_bi_tri = hstack([x_train_uni_bi,train_tri])\n",
    "x_test_uni_bi_tri = hstack([x_test_uni_bi,test_tri])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11797, 30570)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_uni_bi_tri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Started......!\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed: 74.3min remaining: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 93.8min remaining:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 97.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  OneVsRestClassifier(estimator=LogisticRegression(C=0.9, class_weight='balanced',\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn', n_jobs=-1,\n",
      "                                                 penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False),\n",
      "                    n_jobs=-1)\n",
      "Best Cross Validation Score:  0.3250946815542577\n",
      "Accuracy : 0.02673434856175973\n",
      "Hamming loss  0.07082290698505755\n",
      "Micro-average :\n",
      "Precision: 0.2834, Recall: 0.4250, F1-measure: 0.3400\n",
      "Model Ended......!\n"
     ]
    }
   ],
   "source": [
    "#uni bi tri \n",
    "vectorizer_1_6 = CountVectorizer(tokenizer = lambda x: x.split(\" \"), binary='true').fit(y_train)\n",
    "y_train_6 = vectorizer_1_6.transform(y_train)\n",
    "y_test_6 = vectorizer_1_6.transform(y_test)\n",
    "print('model Started......!')\n",
    "\n",
    "alpha = [0.001,0.01,0.1,0.5,0.9,1,1.5,10,100,1000]\n",
    "#penalty = ['l1','l2']\n",
    "\n",
    "params  = {'estimator__C': alpha}\n",
    "clf_estimator_6 = OneVsRestClassifier(LogisticRegression(class_weight='balanced',penalty='l2',n_jobs=-1),n_jobs=-1)\n",
    "RS_clf_6 = RandomizedSearchCV(estimator=clf_estimator_6, param_distributions=params, n_iter=10, cv=5, scoring='f1_micro', n_jobs=-1,verbose=10)\n",
    "RS_clf_6.fit(x_train_uni_bi_tri, y_train_6)\n",
    "print('Best estimator: ',RS_clf_6.best_estimator_)\n",
    "print('Best Cross Validation Score: ',RS_clf_6.best_score_) \n",
    "\n",
    "classifier_6 = RS_clf_6.best_estimator_\n",
    "classifier_6.fit(x_train_uni_bi_tri, y_train_6)\n",
    "predictions_6 = classifier_6.predict(x_test_uni_bi_tri)\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test_6, predictions_6))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test_6,predictions_6))\n",
    "\n",
    "precision_6 = precision_score(y_test_6, predictions_6, average='micro')\n",
    "recall_6 = recall_score(y_test_6, predictions_6, average='micro')\n",
    "f1_6 = f1_score(y_test_6, predictions_6, average='micro')\n",
    " \n",
    "print(\"Micro-average :\") \n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision_6, recall_6, f1_6))\n",
    "print('Model Ended......!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57VQKut6LzHO"
   },
   "source": [
    "<h3> Deep learning LSTM </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVUPBly0MlxT"
   },
   "outputs": [],
   "source": [
    "#data\n",
    "tr_ip1= train_data['pre_pro_plot_synopsis']\n",
    "te_ip1= test_data['pre_pro_plot_synopsis']\n",
    "\n",
    "# prepare tokenizer for train \n",
    "tr = Tokenizer(num_words=10000)\n",
    "tr.fit_on_texts(tr_ip1)\n",
    "vocab_size = len(tr.word_index) + 1\n",
    "# integer encode the documents in train \n",
    "encoded_tr_ip1 = tr.texts_to_sequences(tr_ip1) \n",
    "# integer encode the documents in test \n",
    "encoded_te_ip1 = tr.texts_to_sequences(te_ip1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CfmZabpsMl-g",
    "outputId": "78f6a189-923a-4161-d1a9-801abe9ea6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ip_1_train (11797, 500)\n",
      "shape of ip_1_test (2955, 500)\n"
     ]
    }
   ],
   "source": [
    "#pad documents to a max length of max words\n",
    "max_seq_length = 500 # max length of a pre-processed essay  \n",
    "ip_1_train = pad_sequences(encoded_tr_ip1, maxlen=max_seq_length)\n",
    "print('shape of ip_1_train',ip_1_train.shape)\n",
    "ip_1_test = pad_sequences(encoded_te_ip1, maxlen=max_seq_length)\n",
    "print('shape of ip_1_test',ip_1_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Ho8mutuMmEM"
   },
   "outputs": [],
   "source": [
    "# load the whole embedding into memory \n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5gsUBa8zMmBQ",
    "outputId": "e4c2e1d8-f994-490f-9830-486f9433fb31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111892, 300)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tr.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11797, 71)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\" \"), binary='true').fit(y_train)\n",
    "y_train = vectorizer.transform(y_train)\n",
    "y_test = vectorizer.transform(y_test)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "Dr65WIjcMxMx",
    "outputId": "09df213f-0260-4324-99af-0d3a3f75f1e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 500, 300)          33567600  \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 496, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 124, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 71)                7171      \n",
      "=================================================================\n",
      "Total params: 33,858,899\n",
      "Trainable params: 291,099\n",
      "Non-trainable params: 33,567,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 11797 samples, validate on 2955 samples\n",
      "Epoch 1/10\n",
      "11797/11797 [==============================] - 13s 1ms/step - loss: 13.0214 - accuracy: 0.1044 - val_loss: 11.5835 - val_accuracy: 0.1723\n",
      "Epoch 2/10\n",
      "11797/11797 [==============================] - 10s 852us/step - loss: 13.7986 - accuracy: 0.1499 - val_loss: 12.1839 - val_accuracy: 0.1530\n",
      "Epoch 3/10\n",
      "11797/11797 [==============================] - 10s 825us/step - loss: 16.1579 - accuracy: 0.1494 - val_loss: 15.0776 - val_accuracy: 0.1330\n",
      "Epoch 4/10\n",
      "11797/11797 [==============================] - 10s 842us/step - loss: 19.0781 - accuracy: 0.1313 - val_loss: 15.0543 - val_accuracy: 0.1371\n",
      "Epoch 5/10\n",
      "11797/11797 [==============================] - 10s 853us/step - loss: 22.0941 - accuracy: 0.1319 - val_loss: 21.0597 - val_accuracy: 0.1577\n",
      "Epoch 6/10\n",
      "11797/11797 [==============================] - 10s 835us/step - loss: 25.0698 - accuracy: 0.1327 - val_loss: 18.2127 - val_accuracy: 0.1692\n",
      "Epoch 7/10\n",
      "11797/11797 [==============================] - 10s 865us/step - loss: 28.8377 - accuracy: 0.1266 - val_loss: 27.5180 - val_accuracy: 0.1479\n",
      "Epoch 8/10\n",
      "11797/11797 [==============================] - 10s 837us/step - loss: 34.0514 - accuracy: 0.1128 - val_loss: 30.6786 - val_accuracy: 0.1557\n",
      "Epoch 9/10\n",
      "11797/11797 [==============================] - 10s 838us/step - loss: 40.1147 - accuracy: 0.1113 - val_loss: 23.5263 - val_accuracy: 0.1100\n",
      "Epoch 10/10\n",
      "11797/11797 [==============================] - 10s 837us/step - loss: 46.9542 - accuracy: 0.1045 - val_loss: 28.6237 - val_accuracy: 0.1486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb76e463898>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model \n",
    "model = Sequential() \n",
    "model.add(Embedding(vocab_size,300, weights=[embedding_matrix],trainable=False, input_length=max_seq_length)) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128,5,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(100)) \n",
    "model.add(Dropout(0.2))  \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(71, activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "print(model.summary()) \n",
    "\n",
    "model.fit(ip_1_train, y_train, nb_epoch=10, batch_size=256,validation_data=(ip_1_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtDKABiu0lzt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 28.623673683334324\n",
      "Test accuracy: 0.1485617607831955\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model on test data\n",
    "scores = model.evaluate(ip_1_test, y_test, verbose=0) \n",
    "print('Test loss:', scores[0]) \n",
    "print('Test accuracy:', scores[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Models computed using Simple loop hyperparameter tuning...==========\n",
      "+---------------+------------+------------+------------+--------+----------+\n",
      "|     Model     | vectorizer | best-alpha | Precision  | Recall | F1-score |\n",
      "+---------------+------------+------------+------------+--------+----------+\n",
      "| LOGISTIC REGR | TFIDF-UNI  |    0.1     |    0.27    |  0.38  |   0.32   |\n",
      "| LOGISTIC REGR |  TFIDF-BI  |    1.0     |    0.23    |  0.45  |   0.31   |\n",
      "+---------------+------------+------------+------------+--------+----------+\n",
      "==========Models computed using Randomsearch hyperparameter tuning...==========\n",
      "+---------------+------------------+------------+------------+--------+----------+\n",
      "|     Model     |    vectorizer    | best-alpha | Precision  | Recall | F1-score |\n",
      "+---------------+------------------+------------+------------+--------+----------+\n",
      "| LOGISTIC REGR |    TFIDF-UNI     |    1.0     |    0.29    |  0.42  |   0.34   |\n",
      "| LOGISTIC REGR |     TFIDF-BI     |    1.0     |    0.3     |  0.42  |   0.35   |\n",
      "| LOGISTIC REGR |    TFIDF-TRI     |    1.0     |    0.29    |  0.43  |   0.35   |\n",
      "| LOGISTIC REGR | TFIDF-UNI+BI+TRI |    0.9     |    0.28    |  0.42  |   0.34   |\n",
      "+---------------+------------------+------------+------------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "print('==========Models computed using Simple loop hyperparameter tuning...==========')\n",
    "x.field_names = [ \"Model\",\"vectorizer\", \"best-alpha\", \"Precision \",\"Recall\",\"F1-score\"]\n",
    "x.add_row([\"LOGISTIC REGR\",\"TFIDF-UNI\",      0.1,0.27,0.38,0.32])\n",
    "x.add_row([\"LOGISTIC REGR\",\"TFIDF-BI\",      1.0,0.23,0.45,0.31])\n",
    "print(x)  \n",
    "\n",
    "x2 = PrettyTable()\n",
    "print('==========Models computed using Randomsearch hyperparameter tuning...==========')\n",
    "x2.field_names = [ \"Model\",\"vectorizer\", \"best-alpha\", \"Precision \",\"Recall\",\"F1-score\"]\n",
    "x2.add_row([\"LOGISTIC REGR\",\"TFIDF-UNI\",      1.0,0.29,0.42,0.34])\n",
    "x2.add_row([\"LOGISTIC REGR\",\"TFIDF-BI\",      1.0,0.30,0.42,0.35])\n",
    "x2.add_row([\"LOGISTIC REGR\",\"TFIDF-TRI\",      1.0,0.29,0.43,0.35])\n",
    "x2.add_row([\"LOGISTIC REGR\",\"TFIDF-UNI+BI+TRI\",      0.9,0.28,0.42,0.34])\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGyrpAin8uru"
   },
   "source": [
    "<h3>Observations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MrERNqJi9U95"
   },
   "source": [
    "<ol>\n",
    "  <li>Applied Feature Extraction Topic Modelling to improve the F1-score We got 0.35 for TFIDF Tri grams and BI grams  </li>\n",
    "  <li>Applied Deep learning algorithm LSTM it is not performs good and noticed if we increase the no of layers it crashing the system memory looks like requrie huge computational resources</li>\n",
    "  <li>In previous models we got 0.37 as highest F1-score using 71-Tags by using topic modelling we got 0.35 as F1-score and usig Top-3 and Top-5 Tags we got 0.58 as highest F1-score using Uni-Grams</li>\n",
    "  </ol>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LDA_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
